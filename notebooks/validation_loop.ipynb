{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# CARA: Validation Prototype\n",
                "\n",
                "This notebook implements the \"Patient Actor\" validation loop using:\n",
                "- **Brain**: Google Gemini (`gemini-1.5-flash`)\n",
                "- **Ears**: Local Faster-Whisper (via `cara.engines`)\n",
                "- **Mouth**: Local Chatterbox TTS (via `cara.engines`)\n",
                "\n",
                "### Dependencies\n",
                "This runs **locally** using the `cara-audio` source code."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# 1. Setup Environment & Path\n",
                "import sys\n",
                "import os\n",
                "import asyncio\n",
                "from pathlib import Path\n",
                "from dotenv import load_dotenv\n",
                "\n",
                "# Add ../src to python path so we can import 'cara'\n",
                "project_root = Path(\"..\").resolve()\n",
                "src_path = project_root / \"src\"\n",
                "if str(src_path) not in sys.path:\n",
                "    sys.path.append(str(src_path))\n",
                "\n",
                "load_dotenv() \n",
                "\n",
                "# Gemini Key\n",
                "os.environ[\"GOOGLE_API_KEY\"] = os.getenv(\"GOOGLE_API_KEY\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# 2. Initialize Local Models (STT/TTS)\n",
                "from cara.models import model_manager\n",
                "from cara.config import get_settings\n",
                "from cara.engines.transcription import TranscriptionEngine\n",
                "from cara.utils.audio import audio_to_wav_bytes\n",
                "import torch\n",
                "\n",
                "print(\"\u23f3 Loading Local Models (This may take a moment)...\\n\")\n",
                "if not model_manager.is_loaded:\n",
                "    await model_manager.load_all()\n",
                "print(\"\\n\u2705 Models Loaded! Ready to speak.\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 3. Audio Tools (Local Wrapper)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "import sounddevice as sd\n",
                "from scipy.io.wavfile import write\n",
                "import numpy as np\n",
                "\n",
                "async def listen_local() -> str:\n",
                "    \"\"\"Record Mic -> Save WAV -> Local STT Engine\"\"\"\n",
                "    fs = 44100\n",
                "    duration = 5 # seconds\n",
                "    print(\"\ud83c\udfa4 Listening (5s)...\")\n",
                "    \n",
                "    try:\n",
                "        # Record\n",
                "        recording = sd.rec(int(duration * fs), samplerate=fs, channels=1)\n",
                "        sd.wait()\n",
                "        \n",
                "        # Save temp file\n",
                "        temp_wav = \"input_local.wav\"\n",
                "        write(temp_wav, fs, (recording * 32767).astype(np.int16))\n",
                "        \n",
                "        # Transcribe using Local Engine\n",
                "        print(\"\ud83d\udc42 Transcribing (Local Whisper)...\")\n",
                "        settings = get_settings()\n",
                "        engine = TranscriptionEngine(model_manager.stt, settings)\n",
                "        \n",
                "        # Run in thread pool if needed, but faster-whisper is usually fast enough\n",
                "        result = await engine.transcribe(temp_wav, language=\"it\")\n",
                "        \n",
                "        text = result[\"text\"].strip()\n",
                "        print(f\"\ud83d\udc64 You: {text}\")\n",
                "        return text\n",
                "    except Exception as e:\n",
                "        print(f\"\\n\u26a0\ufe0f Audio Input Error: {e}\")\n",
                "        print(\"Falling back to text input interface.\")\n",
                "        print(\"-\" * 30)\n",
                "        return input(\"Type your message to CARA: \")\n",
                "\n",
                "async def speak_local(text: str):\n",
                "    \"\"\"Text -> Local TTS Engine -> Play\"\"\"\n",
                "    if not text: return\n",
                "    print(f\"\ud83e\udd16 CARA: {text}\")\n",
                "    print(\"\ud83d\udde3\ufe0f Generating Speech (Local Chatterbox)...\")\n",
                "    \n",
                "    # Generate\n",
                "    # Note: Using default speaker. You can pass 'speaker_wav' path here for cloning.\n",
                "    tts_engine = model_manager.tts\n",
                "    \n",
                "    # Run generation in executor to not block\n",
                "    loop = asyncio.get_event_loop()\n",
                "    def _generate():\n",
                "         return tts_engine.generate(\n",
                "            text=text, \n",
                "            language=\"it\", # Multilingual model supports IT\n",
                "            temperature=0.7,\n",
                "            exaggeration=0.5 # Warm/Balanced\n",
                "        )\n",
                "    \n",
                "    wav_tensor = await loop.run_in_executor(None, _generate)\n",
                "    \n",
                "    # Convert to bytes\n",
                "    audio_np = wav_tensor.squeeze().cpu().numpy()\n",
                "    wav_bytes = audio_to_wav_bytes(audio_np.tolist(), sample_rate=tts_engine.sample_rate)\n",
                "    \n",
                "    # Save and Play\n",
                "    with open(\"output_local.wav\", \"wb\") as f:\n",
                "        f.write(wav_bytes)\n",
                "        \n",
                "    # Playback\n",
                "    from IPython.display import Audio, display\n",
                "    display(Audio(\"output_local.wav\", autoplay=True))"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 4. The Brain (LangGraph + Gemini)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "from typing import Annotated, TypedDict\n",
                "from langgraph.graph import StateGraph, START, END\n",
                "from langgraph.graph.message import add_messages\n",
                "from langchain_google_genai import ChatGoogleGenerativeAI\n",
                "from langchain_core.messages import SystemMessage, HumanMessage\n",
                "\n",
                "# State\n",
                "class AgentState(TypedDict):\n",
                "    messages: Annotated[list, add_messages]\n",
                "\n",
                "# Model\n",
                "llm = ChatGoogleGenerativeAI(model=\"gemini-1.5-flash\", temperature=0.7)\n",
                "\n",
                "# Prompt\n",
                "SYSTEM_PROMPT = \"\"\"\n",
                "Sei CARA, un'assistente vocale amorevole per un'anziana signora.\n",
                "Parla IN ITALIANO. Risposte BREVI (massimo 2 frasi).\n",
                "Tono: Caldo, premuroso, lento.\n",
                "\"\"\"\n",
                "\n",
                "# Graph\n",
                "def chatbot_node(state: AgentState):\n",
                "    return {\"messages\": [llm.invoke([SystemMessage(content=SYSTEM_PROMPT)] + state[\"messages\"])]}\n",
                "\n",
                "graph_builder = StateGraph(AgentState)\n",
                "graph_builder.add_node(\"chatbot\", chatbot_node)\n",
                "graph_builder.add_edge(START, \"chatbot\")\n",
                "graph_builder.add_edge(\"chatbot\", END)\n",
                "app = graph_builder.compile()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# 5. Run The Loop\n",
                "\n",
                "state = {\"messages\": []}\n",
                "\n",
                "async def run_turn():\n",
                "    # Listen\n",
                "    user_input = await listen_local()\n",
                "    if not user_input:\n",
                "        return\n",
                "        \n",
                "    # Think\n",
                "    print(\"\ud83e\udde0 Thinking...\")\n",
                "    state[\"messages\"].append(HumanMessage(content=user_input))\n",
                "    result = await app.ainvoke(state)\n",
                "    ai_response = result[\"messages\"][-1].content\n",
                "    state[\"messages\"].append(result[\"messages\"][-1])\n",
                "    \n",
                "    # Speak\n",
                "    await speak_local(ai_response)\n",
                "\n",
                "# Run it!\n",
                "await run_turn()"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.10.12"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 2
}