{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# CARA: Validation Prototype\n",
                "\n",
                "This notebook implements the \"Patient Actor\" validation loop using:\n",
                "- **Brain**: Google Gemini (`gemini-1.5-flash`)\n",
                "- **Ears**: Local Faster-Whisper (via `cara.engines`)\n",
                "- **Mouth**: Local Chatterbox TTS (via `cara.engines`)\n",
                "\n",
                "### Dependencies\n",
                "This runs **locally** using the `cara-audio` source code."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 1,
            "metadata": {},
            "outputs": [],
            "source": [
                "# 1. Setup Environment & Path\n",
                "import sys\n",
                "import os\n",
                "import asyncio\n",
                "from pathlib import Path\n",
                "from dotenv import load_dotenv\n",
                "\n",
                "# Add ../src to python path so we can import 'cara'\n",
                "project_root = Path(\"..\").resolve()\n",
                "src_path = project_root / \"src\"\n",
                "if str(src_path) not in sys.path:\n",
                "    sys.path.append(str(src_path))\n",
                "\n",
                "load_dotenv() \n",
                "\n",
                "# Gemini Key\n",
                "os.environ[\"GOOGLE_API_KEY\"] = os.getenv(\"GOOGLE_API_KEY\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 2,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "‚è≥ Loading Local Models (This may take a moment)...\n",
                        "\n"
                    ]
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "/home/elle/miniconda3/envs/cara-audio/lib/python3.11/site-packages/perth/perth_net/__init__.py:1: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.\n",
                        "  from pkg_resources import resource_filename\n",
                        "/home/elle/miniconda3/envs/cara-audio/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
                        "  from .autonotebook import tqdm as notebook_tqdm\n",
                        "Fetching 6 files: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 6/6 [00:00<00:00, 6741.45it/s]\n",
                        "/home/elle/miniconda3/envs/cara-audio/lib/python3.11/site-packages/diffusers/models/lora.py:393: FutureWarning: `LoRACompatibleLinear` is deprecated and will be removed in version 1.0.0. Use of `LoRACompatibleLinear` is deprecated. Please switch to PEFT backend by installing PEFT: `pip install peft`.\n",
                        "  deprecate(\"LoRACompatibleLinear\", \"1.0.0\", deprecation_message)\n"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "loaded PerthNet (Implicit) at step 250,000\n",
                        "\n",
                        "‚úÖ Models Loaded! Ready to speak.\n"
                    ]
                }
            ],
            "source": [
                "# 2. Initialize Local Models (STT/TTS)\n",
                "from cara.models import model_manager\n",
                "from cara.engines.streaming import StreamingTTSEngine\n",
                "from cara.config import get_settings\n",
                "from cara.engines.transcription import TranscriptionEngine\n",
                "from cara.utils.audio import audio_to_wav_bytes\n",
                "import torch\n",
                "\n",
                "print(\"‚è≥ Loading Local Models (This may take a moment)...\\n\")\n",
                "if not model_manager.is_loaded:\n",
                "    await model_manager.load_all()\n",
                "print(\"\\n‚úÖ Models Loaded! Ready to speak.\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 3. Audio Tools (Local Wrapper)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 3,
            "metadata": {},
            "outputs": [],
            "source": [
                "import sounddevice as sd\n",
                "from scipy.io.wavfile import write\n",
                "import numpy as np\n",
                "import collections\n",
                "\n",
                "# VAD Parameters\n",
                "SAMPLE_RATE = 16000 # Whisper likes 16k\n",
                "BLOCK_SIZE = 1024 # Buffer size\n",
                "THRESHOLD = 0.02 # Startup energy threshold\n",
                "SILENCE_THRESHOLD = 0.015 # End-of-speech threshold\n",
                "SILENCE_DURATION = 1.0 # Seconds of silence to trigger stop\n",
                "MAX_DURATION = 30.0 # Safety cutoff\n",
                "\n",
                "async def listen_local() -> str:\n",
                "    \"\"\"Records audio with Voice Activity Detection (VAD)\"\"\"\n",
                "    print(\"üé§ Listening... (Start speaking to activate)\")\n",
                "    \n",
                "    q = collections.deque(maxlen=int(SAMPLE_RATE * SILENCE_DURATION / BLOCK_SIZE))\n",
                "    recording = []\n",
                "    \n",
                "    # 1. Wait for speech\n",
                "    try:\n",
                "        with sd.InputStream(samplerate=SAMPLE_RATE, channels=1, callback=None, blocksize=BLOCK_SIZE, dtype='float32') as stream:\n",
                "            print(\"   [Waiting for voice...]\")\n",
                "            while True:\n",
                "                indata, _ = stream.read(BLOCK_SIZE)\n",
                "                rms = np.sqrt(np.mean(indata**2))\n",
                "                if rms > THRESHOLD:\n",
                "                    print(\"   [Detected Voice! Recording...]\")\n",
                "                    recording.append(indata)\n",
                "                    break\n",
                "            \n",
                "            # 2. Record until silence\n",
                "            silence_start = None\n",
                "            while True:\n",
                "                indata, _ = stream.read(BLOCK_SIZE)\n",
                "                recording.append(indata)\n",
                "                rms = np.sqrt(np.mean(indata**2))\n",
                "                \n",
                "                if rms < SILENCE_THRESHOLD:\n",
                "                    if silence_start is None:\n",
                "                        silence_start = stream.time\n",
                "                    elif stream.time - silence_start > SILENCE_DURATION:\n",
                "                        print(\"   [Silence detected. Stopping.]\")\n",
                "                        break\n",
                "                else:\n",
                "                    silence_start = None\n",
                "                    \n",
                "                if len(recording) * BLOCK_SIZE / SAMPLE_RATE > MAX_DURATION:\n",
                "                     print(\"   [Max duration reached.]\")\n",
                "                     break\n",
                "\n",
                "        # 3. Save\n",
                "        if not recording:\n",
                "             return \"\"\n",
                "\n",
                "        full_audio = np.concatenate(recording, axis=0)\n",
                "        \n",
                "        # Save temp file\n",
                "        temp_wav = \"input_local.wav\"\n",
                "        # Scale float32 (-1..1) to int16 for wavfile write\n",
                "        write(temp_wav, SAMPLE_RATE, (full_audio * 32767).astype(np.int16))\n",
                "        \n",
                "        # Transcribe using Local Engine\n",
                "        print(\"üëÇ Transcribing (Local Whisper)...\")\n",
                "        settings = get_settings()\n",
                "        engine = TranscriptionEngine(model_manager.stt, settings)\n",
                "        \n",
                "        result = await engine.transcribe(temp_wav, language=\"it\")\n",
                "        \n",
                "        text = result[\"text\"].strip()\n",
                "        print(f\"üë§ You: {text}\")\n",
                "        return text\n",
                "\n",
                "    except Exception as e:\n",
                "        print(f\"\\n‚ö†Ô∏è Audio Input Error: {e}\")\n",
                "        return \"\"\n",
                "\n",
                "async def speak_local(text: str):\n",
                "    \"\"\"Text -> Local TTS Streaming -> Play Live\"\"\"\n",
                "    if not text: return\n",
                "    print(f\"ü§ñ CARA: {text}\")\n",
                "    print(\"üó£Ô∏è Speaking (Streaming)...\")\n",
                "    \n",
                "    tts_engine = model_manager.tts\n",
                "    settings = get_settings()\n",
                "    stream_engine = StreamingTTSEngine(tts_engine, settings)\n",
                "    \n",
                "    try:\n",
                "        # Open a Raw stream for PCM16 data\n",
                "        stream = sd.RawOutputStream(\n",
                "            samplerate=tts_engine.sample_rate,\n",
                "            channels=1,\n",
                "            dtype='int16' # PCM16\n",
                "        )\n",
                "        stream.start()\n",
                "        \n",
                "        async for chunk in stream_engine.stream(text, language=\"it\"):\n",
                "            stream.write(chunk)\n",
                "            \n",
                "        stream.stop()\n",
                "        stream.close()\n",
                "    except Exception as e:\n",
                "        print(f\"Streaming Error: {e}\")\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 4. The Brain (LangGraph + Gemini)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 4,
            "metadata": {},
            "outputs": [],
            "source": [
                "from typing import Annotated, TypedDict\n",
                "from langgraph.graph import StateGraph, START, END\n",
                "from langgraph.graph.message import add_messages\n",
                "from langchain_google_genai import ChatGoogleGenerativeAI\n",
                "from langchain_core.messages import SystemMessage, HumanMessage\n",
                "\n",
                "# State\n",
                "class AgentState(TypedDict):\n",
                "    messages: Annotated[list, add_messages]\n",
                "\n",
                "# Model\n",
                "llm = ChatGoogleGenerativeAI(model=\"gemini-3-flash-preview\", temperature=0.7)\n",
                "\n",
                "# Prompt\n",
                "SYSTEM_PROMPT = \"\"\"\n",
                "Sei CARA, un'assistente vocale amorevole per un'anziana signora.\n",
                "Parla IN ITALIANO. Risposte BREVI (massimo 2 frasi).\n",
                "Tono: Caldo, premuroso, lento.\n",
                "\"\"\"\n",
                "\n",
                "# Graph\n",
                "def chatbot_node(state: AgentState):\n",
                "    return {\"messages\": [llm.invoke([SystemMessage(content=SYSTEM_PROMPT)] + state[\"messages\"])]}\n",
                "\n",
                "graph_builder = StateGraph(AgentState)\n",
                "graph_builder.add_node(\"chatbot\", chatbot_node)\n",
                "graph_builder.add_edge(START, \"chatbot\")\n",
                "graph_builder.add_edge(\"chatbot\", END)\n",
                "app = graph_builder.compile()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 5,
            "metadata": {},
            "outputs": [],
            "source": [
                "# 5. Run The Loop\n",
                "\n",
                "state = {\"messages\": []}"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 6,
            "metadata": {},
            "outputs": [],
            "source": [
                "async def run_loop():\n",
                "    print(\"üîÅ Starting Conversation Loop. Press Ctrl+C directly in the kernel to stop.\")\n",
                "    while True:\n",
                "        # Listen\n",
                "        user_input = await listen_local()\n",
                "        if not user_input:\n",
                "            # No speech detected or error, just continue listening\n",
                "            continue\n",
                "            \n",
                "        # Think\n",
                "        print(\"üß† Thinking...\")\n",
                "        state[\"messages\"].append(HumanMessage(content=user_input))\n",
                "        result = await app.ainvoke(state)\n",
                "        ai_response = result[\"messages\"][-1].content\n",
                "        if isinstance(ai_response, list):\n",
                "            ai_response = \" \".join([block[\"text\"] for block in ai_response if \"text\" in block])\n",
                "        state[\"messages\"].append(result[\"messages\"][-1])\n",
                "        \n",
                "        # Speak\n",
                "        await speak_local(ai_response)\n",
                "\n",
                "# Run it!\n",
                "try:\n",
                "    await run_loop()\n",
                "except KeyboardInterrupt:\n",
                "    print(\"\\nüõë Loop Stopped by User.\")"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "cara-audio",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.11.14"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 2
}